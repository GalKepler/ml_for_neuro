

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Exercise VIII: K-Means Clustering and PCA &#8212; Machine Learning for Neuroscience</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapters/chapter_08/exercise_08';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Exercise IX: The Haxby Experiment (2001)" href="../chapter_09/exercise_09.html" />
    <link rel="prev" title="Exercise VII: Decision Trees and Random Forests" href="../chapter_07/exercise_07.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="Machine Learning for Neuroscience - Home"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="Machine Learning for Neuroscience - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../syllabus.html">Syllabus</a></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../../content.html">Contents</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../chapter_01/exercise_01.html">Exercise I: Exploratory Data Analysis (EDA)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_02/exercise_02.html">Exercise II: k-Nearest Neighbors (k-NN)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/exercise_03.html">Exercise III: Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../catching_up/catching_up.html">Catching Up</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/exercise_04.html">Exercise IV: Logistic Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_05/exercise_05.html">Exercise V: Regularization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/exercise_06.html">Exercise VI: Revisiting Linear and Logistic Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/exercise_07.html">Exercise VII: Decision Trees and Random Forests</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Exercise VIII: K-Means Clustering and PCA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_09/exercise_09.html">Exercise IX: The Haxby Experiment (2001)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../resources.html">Resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../references.html">References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/GalKepler/ml_for_neuro" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/GalKepler/ml_for_neuro/issues/new?title=Issue%20on%20page%20%2Fchapters/chapter_08/exercise_08.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/chapters/chapter_08/exercise_08.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Exercise VIII: K-Means Clustering and PCA</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#iris-dataset">Iris Dataset</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#set-up">Set up</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dimensionality-reduction-using-principal-component-analysis-pca">Dimensionality Reduction using Principal Component Analysis (PCA)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#k-means-clustering">K-means Clustering</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#clustering-evaluation">Clustering Evaluation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#asd-subtypes-classification">ASD Subtypes Classification</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#principal-component-analysis-pca">Principal Component Analysis (PCA)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">K-Means Clustering</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Clustering Evaluation</a></li>
</ul>
</li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="exercise-viii-k-means-clustering-and-pca">
<h1>Exercise VIII: K-Means Clustering and PCA<a class="headerlink" href="#exercise-viii-k-means-clustering-and-pca" title="Permalink to this heading">#</a></h1>
<section id="iris-dataset">
<h2>Iris Dataset<a class="headerlink" href="#iris-dataset" title="Permalink to this heading">#</a></h2>
<p>Let’s start things off with a simple application of our subject material on the Iris dataset to better understand our workflow and the relevant metrics.</p>
<section id="set-up">
<h3>Set up<a class="headerlink" href="#set-up" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>


<span class="n">data</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">(</span><span class="n">as_frame</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">X_iris</span><span class="p">,</span> <span class="n">y_iris</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>
<span class="n">y_iris</span> <span class="o">=</span> <span class="n">y_iris</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span>
    <span class="p">{</span><span class="n">index</span><span class="p">:</span> <span class="n">name</span>
     <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;target_names&quot;</span><span class="p">])})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/tmp/ipykernel_2205/592460860.py:1: DeprecationWarning: 
Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),
(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)
but was not found to be installed on your system.
If this would cause problems for you,
please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466
        
  import pandas as pd
</pre></div>
</div>
</div>
</div>
</section>
<section id="dimensionality-reduction-using-principal-component-analysis-pca">
<h3>Dimensionality Reduction using <a class="reference external" href="https://en.wikipedia.org/wiki/Principal_component_analysis">Principal Component Analysis (PCA)</a><a class="headerlink" href="#dimensionality-reduction-using-principal-component-analysis-pca" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>

<span class="n">IRIS_N_COMPONENTS</span> <span class="o">=</span> <span class="n">X_iris</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>

<span class="n">iris_pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">IRIS_N_COMPONENTS</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">iris_pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_iris</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s try and evaluate how well did PCA manage to find small number of components to explain the variance:</p>
<div class="dropdown tip admonition">
<p class="admonition-title">plots/utils.py</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Provides utility functions for creating plots in exercise 8.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Union</span>


<span class="k">def</span> <span class="nf">organize_kwargs</span><span class="p">(</span>
    <span class="n">user_kwargs</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">default_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Update default keyword argument configuration with user provided</span>
<span class="sd">    configuration.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    user_kwargs: Union[dict, None]</span>
<span class="sd">        Dictionary of user provided keyword argument configurations, or</span>
<span class="sd">        None</span>
<span class="sd">    default_kwargs: dict</span>
<span class="sd">        Default keyword argument configuration to be updated with user</span>
<span class="sd">        configuration</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    dict</span>
<span class="sd">        Complete keyword argument configuration</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">kwargs</span> <span class="o">=</span> <span class="n">user_kwargs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="n">default_kwargs</span> <span class="o">=</span> <span class="n">default_kwargs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="k">return</span> <span class="p">{</span><span class="o">**</span><span class="n">default_kwargs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">}</span>
</pre></div>
</div>
</div>
<div class="dropdown tip admonition">
<p class="admonition-title">plots/explained_variance.py</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Functions creating plots to evaluate explained variance.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">from</span> <span class="nn">plots.utils</span> <span class="kn">import</span> <span class="n">organize_kwargs</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>


<span class="n">DEFAULT_FIG_KWARGS</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;figsize&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">6</span><span class="p">)}</span>
<span class="n">DEFAULT_COMPONENT_AX_KWARGS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;color&quot;</span><span class="p">:</span> <span class="s2">&quot;purple&quot;</span><span class="p">,</span>
    <span class="s2">&quot;linewidth&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
    <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="s2">&quot;Individual Component&quot;</span><span class="p">,</span>
<span class="p">}</span>
<span class="n">DEFAULT_CUMULATIVE_AX_KWARGS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;color&quot;</span><span class="p">:</span> <span class="s2">&quot;orange&quot;</span><span class="p">,</span>
    <span class="s2">&quot;linewidth&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
    <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="s2">&quot;Cumulative&quot;</span><span class="p">,</span>
<span class="p">}</span>
<span class="n">DEFAULT_CUSTOMIZATIONS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;title&quot;</span><span class="p">:</span> <span class="s2">&quot;Explained Variance Ratio by Number of Principal Components&quot;</span><span class="p">,</span>
    <span class="s2">&quot;xlabel&quot;</span><span class="p">:</span> <span class="s2">&quot;Number of Principal Components&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ylabel&quot;</span><span class="p">:</span> <span class="s2">&quot;Explained Variance Ratio&quot;</span><span class="p">,</span>
<span class="p">}</span>
<span class="n">DEFAULT_LEGEND_LOCATION</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.85</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">plot_explained_variance_ratio</span><span class="p">(</span>
    <span class="n">pca</span><span class="p">:</span> <span class="n">PCA</span><span class="p">,</span>
    <span class="n">fig_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">component_ax_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">cumulative_ax_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">customizations</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">legend_location</span><span class="p">:</span> <span class="nb">tuple</span> <span class="o">=</span> <span class="n">DEFAULT_LEGEND_LOCATION</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Plot explained variance by component number for a fitted PCA estimator.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    pca : PCA</span>
<span class="sd">        Fitted PCA model</span>
<span class="sd">    fig_kwargs : dict</span>
<span class="sd">        Keyword arguments passed to the created figure</span>
<span class="sd">    component_ax_kwargs : dict</span>
<span class="sd">        Keyword arguments passed in the explained variance by individual</span>
<span class="sd">        component plot call</span>
<span class="sd">    cumulative_ax_kwargs : dict</span>
<span class="sd">        Keyword arguments passed in the cumulative explained variance by</span>
<span class="sd">        component plot call</span>
<span class="sd">    customizations : dict</span>
<span class="sd">        Keyword arguments passed to the axis&#39; `set()` method</span>
<span class="sd">    legend_location: Tuple(float, float)</span>
<span class="sd">        Legend location within figure</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Tuple(Figure, Axes)</span>
<span class="sd">        Create figure and axes</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Prepare figure and axes kwargs</span>
    <span class="n">fig_kwargs</span> <span class="o">=</span> <span class="n">organize_kwargs</span><span class="p">(</span><span class="n">fig_kwargs</span><span class="p">,</span> <span class="n">DEFAULT_FIG_KWARGS</span><span class="p">)</span>
    <span class="n">component_ax_kwargs</span> <span class="o">=</span> <span class="n">organize_kwargs</span><span class="p">(</span>
        <span class="n">component_ax_kwargs</span><span class="p">,</span> <span class="n">DEFAULT_COMPONENT_AX_KWARGS</span>
    <span class="p">)</span>
    <span class="n">cumulative_ax_kwargs</span> <span class="o">=</span> <span class="n">organize_kwargs</span><span class="p">(</span>
        <span class="n">cumulative_ax_kwargs</span><span class="p">,</span> <span class="n">DEFAULT_CUMULATIVE_AX_KWARGS</span>
    <span class="p">)</span>
    <span class="n">customizations</span> <span class="o">=</span> <span class="n">organize_kwargs</span><span class="p">(</span><span class="n">customizations</span><span class="p">,</span> <span class="n">DEFAULT_CUSTOMIZATIONS</span><span class="p">)</span>

    <span class="c1"># Create figure</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="o">**</span><span class="n">fig_kwargs</span><span class="p">)</span>

    <span class="c1"># Plot explained variance ratio by component</span>
    <span class="n">x_range</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">pca</span><span class="o">.</span><span class="n">n_components_</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span> <span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">,</span> <span class="o">**</span><span class="n">component_ax_kwargs</span><span class="p">)</span>

    <span class="c1"># Plot cumulative explained variance</span>
    <span class="n">cumulative_sum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span> <span class="n">cumulative_sum</span><span class="p">,</span> <span class="o">**</span><span class="n">cumulative_ax_kwargs</span><span class="p">)</span>

    <span class="c1">#</span>
    <span class="c1"># Customizations</span>
    <span class="c1">#</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="o">**</span><span class="n">customizations</span><span class="p">)</span>

    <span class="c1"># Add legend</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">bbox_to_anchor</span><span class="o">=</span><span class="n">legend_location</span><span class="p">)</span>

    <span class="c1"># Fix x-axis tick labels to show integers</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">x_range</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">x_range</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span>


<span class="k">def</span> <span class="nf">create_explained_variance_df</span><span class="p">(</span><span class="n">pca</span><span class="p">:</span> <span class="n">PCA</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a formatted dataframe to display the plot&#39;s information</span>
<span class="sd">    conveniently.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    pca : PCA</span>
<span class="sd">        Fitted PCA model</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pd.DataFrame</span>
<span class="sd">        Explained variance (per component and cumulative)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">results_dict</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;Individual Component&quot;</span><span class="p">:</span> <span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">,</span>
        <span class="s2">&quot;Cumulative&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">),</span>
    <span class="p">}</span>
    <span class="n">index</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">pca</span><span class="o">.</span><span class="n">n_components_</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results_dict</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">index</span><span class="p">)</span>
    <span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;# Components&quot;</span>
    <span class="k">return</span> <span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">plots.explained_variance</span> <span class="kn">import</span> <span class="n">create_explained_variance_df</span><span class="p">,</span> <span class="n">plot_explained_variance_ratio</span>


<span class="c1"># Create explained variance ratio figure</span>
<span class="n">fig_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;figsize&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">)}</span>
<span class="n">iris_explained_variance_fig</span><span class="p">,</span> <span class="n">iris_explained_variance_ax</span> <span class="o">=</span> <span class="n">plot_explained_variance_ratio</span><span class="p">(</span>
    <span class="n">iris_pca</span><span class="p">,</span> <span class="n">fig_kwargs</span><span class="o">=</span><span class="n">fig_kwargs</span><span class="p">)</span>

<span class="c1"># Create explained variance ratio dataframe</span>
<span class="n">explained_variance_df</span> <span class="o">=</span> <span class="n">create_explained_variance_df</span><span class="p">(</span><span class="n">iris_pca</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_remove-input docutils container">
</div>
<div class="cell tag_remove-input docutils container">
</div>
<p>We’ve managed to capture <span class="pasted-text">97.77</span>% of the variance using only 2 components, and <span class="pasted-text">99.48</span>% percent using 3, not bad at all!</p>
<p>To calculate the coordinates of the dataset in the dimensions of the calculated principal components, we have to call <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA.transform"><code class="docutils literal notranslate"><span class="pre">tranform()</span></code></a>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_iris_reduced</span> <span class="o">=</span> <span class="n">iris_pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_iris</span><span class="p">)</span>
<span class="n">X_iris_reduced</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(150, 3)
</pre></div>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As with many other classes that implement this general procedure, <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> also provides a <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA.fit_transform"><code class="docutils literal notranslate"><span class="pre">fit_transform()</span></code></a> function to do both more conveniently.</p>
</div>
<p>Fortunately, 2 and 3 dimensions are also simple enough to visualize:</p>
<div class="dropdown tip admonition">
<p class="admonition-title">plots/pca_scatter.py</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">interact</span>

<span class="n">DEFAULT_TITLE</span> <span class="o">=</span> <span class="s2">&quot;Dataset Projected Over </span><span class="si">{n_dimensions}</span><span class="s2"> Dimensions Using PCA&quot;</span>
<span class="n">PCA_AXIS_LABELS_2D</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;xlabel&quot;</span><span class="p">:</span> <span class="s2">&quot;Principal Component #1&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ylabel&quot;</span><span class="p">:</span> <span class="s2">&quot;Principal Component #2&quot;</span><span class="p">,</span>
<span class="p">}</span>
<span class="n">PCA_AXIS_LABELS_3D</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;xlabel&quot;</span><span class="p">:</span> <span class="s2">&quot;Principal Component #1&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ylabel&quot;</span><span class="p">:</span> <span class="s2">&quot;Principal Component #2&quot;</span><span class="p">,</span>
    <span class="s2">&quot;zlabel&quot;</span><span class="p">:</span> <span class="s2">&quot;Principal Component #3&quot;</span><span class="p">,</span>
<span class="p">}</span>


<span class="k">def</span> <span class="nf">plot_reduced</span><span class="p">(</span>
    <span class="n">X_reduced</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">classification_labels</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">true_labels</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">title</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Plots a 3D or 2D scatter plot of *X_reduced*, potentially colored by</span>
<span class="sd">    *classification_labels* and marked by equality with *true_labels* (if</span>
<span class="sd">    provided).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X_reduced : np.ndarray</span>
<span class="sd">        Dimensionality-reduced dataset</span>
<span class="sd">    classification_labels : np.ndarray, optional</span>
<span class="sd">        Classification results to use for color mapping, by default None</span>
<span class="sd">    true_labels : np.ndarray, optional</span>
<span class="sd">        Real labels to use for marker styling, by default None</span>
<span class="sd">    title : str, optional</span>
<span class="sd">        Custom title, by default None</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Generate a default title if required</span>
    <span class="n">n_dimensions</span> <span class="o">=</span> <span class="n">X_reduced</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">title</span> <span class="o">=</span> <span class="n">title</span> <span class="ow">or</span> <span class="n">DEFAULT_TITLE</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n_dimensions</span><span class="o">=</span><span class="n">n_dimensions</span><span class="p">)</span>

    <span class="c1"># Create a classification_success mask array if required</span>
    <span class="n">classification_success</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">true_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">classification_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">classification_success</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">true_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="n">part_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">true_labels</span><span class="p">)</span> <span class="o">//</span> <span class="mi">3</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
            <span class="n">start_index</span> <span class="o">=</span> <span class="n">i</span> <span class="o">*</span> <span class="n">part_length</span>
            <span class="n">end_index</span> <span class="o">=</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">part_length</span>
            <span class="n">category_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span>
                <span class="n">classification_labels</span><span class="p">[</span><span class="n">start_index</span><span class="p">:</span><span class="n">end_index</span><span class="p">]</span>
            <span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span>
            <span class="n">part_labels</span> <span class="o">=</span> <span class="n">classification_labels</span><span class="p">[</span><span class="n">start_index</span><span class="p">:</span><span class="n">end_index</span><span class="p">]</span>
            <span class="n">classification_success</span><span class="p">[</span><span class="n">start_index</span><span class="p">:</span><span class="n">end_index</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">part_labels</span> <span class="o">==</span> <span class="n">category_label</span>
            <span class="p">)</span>

    <span class="c1"># Generate plot by number of dimensions</span>
    <span class="k">if</span> <span class="n">n_dimensions</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
        <span class="c1"># Create 3D scatter plot</span>
        <span class="k">def</span> <span class="nf">plot_3d_scatter</span><span class="p">(</span><span class="n">elev</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">azim</span><span class="o">=-</span><span class="mi">90</span><span class="p">):</span>
            <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s2">&quot;3d&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">classification_success</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">X_reduced</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">classification_labels</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Plot correct labels</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
                    <span class="o">*</span><span class="n">X_reduced</span><span class="p">[</span><span class="n">classification_success</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span>
                    <span class="n">c</span><span class="o">=</span><span class="n">classification_labels</span><span class="p">[</span><span class="n">classification_success</span><span class="p">],</span>
                    <span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="c1"># Plot incorrect labels</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
                    <span class="o">*</span><span class="n">X_reduced</span><span class="p">[</span><span class="o">~</span><span class="n">classification_success</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span>
                    <span class="n">c</span><span class="o">=</span><span class="n">classification_labels</span><span class="p">[</span><span class="o">~</span><span class="n">classification_success</span><span class="p">],</span>
                    <span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span>
                    <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="o">**</span><span class="n">PCA_AXIS_LABELS_3D</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">view_init</span><span class="p">(</span><span class="n">elev</span><span class="p">,</span> <span class="n">azim</span><span class="p">)</span>

        <span class="n">interact</span><span class="p">(</span><span class="n">plot_3d_scatter</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">n_dimensions</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="c1"># Create 2D scatter plot</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">classification_success</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">X_reduced</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">classification_labels</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">success</span> <span class="o">=</span> <span class="n">X_reduced</span><span class="p">[</span><span class="n">classification_success</span><span class="p">]</span>
            <span class="n">failure</span> <span class="o">=</span> <span class="n">X_reduced</span><span class="p">[</span><span class="o">~</span><span class="n">classification_success</span><span class="p">]</span>
            <span class="c1"># Plot correct labels</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
                <span class="o">*</span><span class="n">success</span><span class="o">.</span><span class="n">T</span><span class="p">,</span>
                <span class="n">c</span><span class="o">=</span><span class="n">classification_labels</span><span class="p">[</span><span class="n">classification_success</span><span class="p">],</span>
                <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Correct Label&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="c1"># Plot incorrect labels</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
                <span class="o">*</span><span class="n">failure</span><span class="o">.</span><span class="n">T</span><span class="p">,</span>
                <span class="n">c</span><span class="o">=</span><span class="n">classification_labels</span><span class="p">[</span><span class="o">~</span><span class="n">classification_success</span><span class="p">],</span>
                <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">,</span>
                <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Incorrect Label&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper center&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
            <span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">,</span>
            <span class="o">**</span><span class="n">PCA_AXIS_LABELS_2D</span><span class="p">,</span>
        <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">plots.pca_scatter</span> <span class="kn">import</span> <span class="n">plot_reduced</span>


<span class="n">y_iris_labels</span> <span class="o">=</span> <span class="n">y_iris</span><span class="o">.</span><span class="n">replace</span><span class="p">({</span><span class="s2">&quot;setosa&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;versicolor&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;virginica&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">})</span><span class="o">.</span><span class="n">values</span>

<span class="n">plot_reduced</span><span class="p">(</span><span class="n">X_iris_reduced</span><span class="p">,</span> <span class="n">y_iris_labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">7</span><span class="p">],</span> <span class="n">line</span> <span class="mi">1</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="kn">from</span> <span class="nn">plots.pca_scatter</span> <span class="kn">import</span> <span class="n">plot_reduced</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="n">y_iris_labels</span> <span class="o">=</span> <span class="n">y_iris</span><span class="o">.</span><span class="n">replace</span><span class="p">({</span><span class="s2">&quot;setosa&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;versicolor&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;virginica&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">})</span><span class="o">.</span><span class="n">values</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="n">plot_reduced</span><span class="p">(</span><span class="n">X_iris_reduced</span><span class="p">,</span> <span class="n">y_iris_labels</span><span class="p">)</span>

<span class="n">File</span> <span class="o">~/</span><span class="n">work</span><span class="o">/</span><span class="n">ml_for_neuro</span><span class="o">/</span><span class="n">ml_for_neuro</span><span class="o">/</span><span class="n">ml_for_neuro</span><span class="o">/</span><span class="n">chapters</span><span class="o">/</span><span class="n">chapter_08</span><span class="o">/</span><span class="n">plots</span><span class="o">/</span><span class="n">pca_scatter</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">3</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="ne">----&gt; </span><span class="mi">3</span> <span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">interact</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="n">DEFAULT_TITLE</span> <span class="o">=</span> <span class="s2">&quot;Dataset Projected Over </span><span class="si">{n_dimensions}</span><span class="s2"> Dimensions Using PCA&quot;</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="n">PCA_AXIS_LABELS_2D</span> <span class="o">=</span> <span class="p">{</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span>     <span class="s2">&quot;xlabel&quot;</span><span class="p">:</span> <span class="s2">&quot;Principal Component #1&quot;</span><span class="p">,</span>
<span class="g g-Whitespace">      </span><span class="mi">8</span>     <span class="s2">&quot;ylabel&quot;</span><span class="p">:</span> <span class="s2">&quot;Principal Component #2&quot;</span><span class="p">,</span>
<span class="g g-Whitespace">      </span><span class="mi">9</span> <span class="p">}</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;ipywidgets&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_reduced</span><span class="p">(</span><span class="n">X_iris_reduced</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">],</span> <span class="n">true_labels</span><span class="o">=</span><span class="n">y_iris_labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Ah, we can already guess the <code class="docutils literal notranslate"><span class="pre">setosa</span></code> class to be that discernible cloud on the left of both dimensionality-reduced scatters.</p>
</section>
<section id="k-means-clustering">
<h3><a class="reference external" href="https://en.wikipedia.org/wiki/K-means_clustering">K-means</a> Clustering<a class="headerlink" href="#k-means-clustering" title="Permalink to this heading">#</a></h3>
<p>Next, we could try and identify the underlying classes or Iris genera and comparing our results against the actual labels. Essentially, we are checking how does the reduction of the feature space using PCA impact our ability to detect the different iris genera using K-means clustering.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>


<span class="n">N_IRIS_CLASSES</span> <span class="o">=</span> <span class="mi">3</span>

<span class="n">iris_kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">N_IRIS_CLASSES</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Note that this is an educational example meant to improve our understanding of dimensionality reduction and clustering, not to represent a relevant use case for clustering. In most cases, clustering is an appealing choice when we don’t actually know the labels (which is why it is considered an <em>unsupervised</em> learning method).</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">iris_labels_4</span> <span class="o">=</span> <span class="n">iris_kmeans</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X_iris</span><span class="p">)</span>
<span class="n">iris_labels_3</span> <span class="o">=</span> <span class="n">iris_kmeans</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X_iris_reduced</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">3</span><span class="p">])</span>
<span class="n">iris_labels_2</span> <span class="o">=</span> <span class="n">iris_kmeans</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X_iris_reduced</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">])</span>
<span class="n">iris_labels_1</span> <span class="o">=</span> <span class="n">iris_kmeans</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X_iris_reduced</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Again, we’ll plot the observations in their reduced spaces, only this time we will include the <span style="color:red">cluster index</span> (represented with the <span style="color:red">color</span> of each observation), as well as the classification’s success relative to the <strong>true labels</strong> (represented with <strong>circles for correct versus “X” for incorrect</strong> classifications).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_reduced</span><span class="p">(</span><span class="n">X_iris_reduced</span><span class="p">,</span> <span class="n">iris_labels_3</span><span class="p">,</span> <span class="n">y_iris_labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/8796e566805a254cd8b85c67384919d85cf13e5510f2d4cf0f072ea6dd197a82.png" src="../../_images/8796e566805a254cd8b85c67384919d85cf13e5510f2d4cf0f072ea6dd197a82.png" />
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "ed3b59801e944e62af0d537ace27d07d", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_reduced</span><span class="p">(</span><span class="n">X_iris_reduced</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">],</span> <span class="n">iris_labels_2</span><span class="p">,</span> <span class="n">y_iris_labels</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/dc62c9c91f65b2c51787957e4ea698e9b6375bb11f00b39795cd794edf402e9a.png" src="../../_images/dc62c9c91f65b2c51787957e4ea698e9b6375bb11f00b39795cd794edf402e9a.png" />
</div>
</div>
<section id="clustering-evaluation">
<h4>Clustering Evaluation<a class="headerlink" href="#clustering-evaluation" title="Permalink to this heading">#</a></h4>
<p>How do you think we did relative to the baseline (clustering using all 4 features) as we reduced the dimensionality of the dataset?</p>
<div class="dropdown tip admonition">
<p class="admonition-title">plots/accuracy.py</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">permutations</span>
<span class="kn">from</span> <span class="nn">plots.utils</span> <span class="kn">import</span> <span class="n">organize_kwargs</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Iterable</span><span class="p">,</span> <span class="n">Tuple</span>

<span class="n">DEFAULT_FIGURE_KWARGS</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;figsize&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">)}</span>
<span class="n">DEFAULT_AXES_KWARGS</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;marker&quot;</span><span class="p">:</span> <span class="s2">&quot;o&quot;</span><span class="p">}</span>
<span class="n">DEFAULT_CUSTOMIZATIONS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;title&quot;</span><span class="p">:</span> <span class="s2">&quot;Accuracy by Number of Principal Components&quot;</span><span class="p">,</span>
    <span class="s2">&quot;xlabel&quot;</span><span class="p">:</span> <span class="s2">&quot;Number of Principal Components&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ylabel&quot;</span><span class="p">:</span> <span class="s2">&quot;Accuracy Score&quot;</span><span class="p">,</span>
<span class="p">}</span>


<span class="k">def</span> <span class="nf">plot_accuracy_by_pc</span><span class="p">(</span>
    <span class="n">classification_labels</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">,</span>
    <span class="n">true_labels</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">fig_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">ax_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">customizations</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">plt</span><span class="o">.</span><span class="n">Figure</span><span class="p">,</span> <span class="n">plt</span><span class="o">.</span><span class="n">Axes</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Plot accuracy scores by number of principal components.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    classification_labels : Iterable</span>
<span class="sd">        Classification labels estimated by clustering each subset of principal</span>
<span class="sd">        components</span>
<span class="sd">    true_labels : np.ndarray</span>
<span class="sd">        True classification classes</span>
<span class="sd">    fig_kwargs : dict, optional</span>
<span class="sd">        Keyword arguments passed to the created figure, by default None</span>
<span class="sd">    ax_kwargs : dict, optional</span>
<span class="sd">        Keyword arguments passed to the created axis, by default None</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Tuple[plt.Figure, plt.Axes]</span>
<span class="sd">        Created figure and axis</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">fig_kwargs</span> <span class="o">=</span> <span class="n">organize_kwargs</span><span class="p">(</span><span class="n">fig_kwargs</span><span class="p">,</span> <span class="n">DEFAULT_FIGURE_KWARGS</span><span class="p">)</span>
    <span class="n">ax_kwargs</span> <span class="o">=</span> <span class="n">organize_kwargs</span><span class="p">(</span><span class="n">ax_kwargs</span><span class="p">,</span> <span class="n">DEFAULT_AXES_KWARGS</span><span class="p">)</span>
    <span class="n">customizations</span> <span class="o">=</span> <span class="n">organize_kwargs</span><span class="p">(</span><span class="n">customizations</span><span class="p">,</span> <span class="n">DEFAULT_CUSTOMIZATIONS</span><span class="p">)</span>
    <span class="n">distinct_labels</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">true_labels</span><span class="p">))</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">labels_array</span> <span class="ow">in</span> <span class="n">classification_labels</span><span class="p">:</span>
        <span class="n">permuted_scores</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">permutation</span> <span class="ow">in</span> <span class="n">permutations</span><span class="p">(</span><span class="n">distinct_labels</span><span class="p">):</span>
            <span class="n">permuted_true_labels</span> <span class="o">=</span> <span class="n">true_labels</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">permutation</span><span class="p">)):</span>
                <span class="n">permuted_true_labels</span><span class="p">[</span><span class="n">true_labels</span> <span class="o">==</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">permutation</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">permuted_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">accuracy_score</span><span class="p">(</span><span class="n">labels_array</span><span class="p">,</span> <span class="n">permuted_true_labels</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">permuted_scores</span><span class="p">))</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="o">**</span><span class="n">fig_kwargs</span><span class="p">)</span>
    <span class="n">x_range</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="o">**</span><span class="n">ax_kwargs</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xticks</span><span class="o">=</span><span class="n">x_range</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="n">x_range</span><span class="p">,</span> <span class="o">**</span><span class="n">customizations</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span>
</pre></div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">plots.accuracy</span> <span class="kn">import</span> <span class="n">plot_accuracy_by_pc</span>


<span class="n">classification_labels</span> <span class="o">=</span> <span class="p">(</span><span class="n">iris_labels_1</span><span class="p">,</span> <span class="n">iris_labels_2</span><span class="p">,</span> <span class="n">iris_labels_3</span><span class="p">,</span>
                         <span class="n">iris_labels_4</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plot_accuracy_by_pc</span><span class="p">(</span><span class="n">classification_labels</span><span class="p">,</span> <span class="n">y_iris_labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Surprisingly, reducing the dimensionality of the iris dataset to  1 has improved the performance of K-means classification significantly when compared to the true labels.</p>
<p><code class="docutils literal notranslate"><span class="pre">sklearn</span></code>’s <code class="docutils literal notranslate"><span class="pre">metrics</span></code> module also provides us with the <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html#sklearn.metrics.silhouette_score"><code class="docutils literal notranslate"><span class="pre">silhouette_score</span></code></a> metric for evaluating the degree of separation between the clusters:</p>
<div class="dropdown tip admonition">
<p class="admonition-title">plots/silhouette.py</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Functions to plot silhouette scores by either number of principal components</span>
<span class="sd">used to reduce the dataset&#39;s dimensionality or number of clusters used by</span>
<span class="sd">`KMeans`.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">plots.utils</span> <span class="kn">import</span> <span class="n">organize_kwargs</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">silhouette_score</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Iterable</span><span class="p">,</span> <span class="n">Tuple</span>


<span class="c1">#</span>
<span class="c1"># Silhouette scores by number of principal components</span>
<span class="c1">#</span>

<span class="n">DEFAULT_FIGURE_KWARGS</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;figsize&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">)}</span>
<span class="n">DEFAULT_AXES_KWARGS</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;marker&quot;</span><span class="p">:</span> <span class="s2">&quot;o&quot;</span><span class="p">}</span>
<span class="n">DEFAULT_CUSTOMIZATIONS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;title&quot;</span><span class="p">:</span> <span class="s2">&quot;Silhouette Score by Number of Principal Components&quot;</span><span class="p">,</span>
    <span class="s2">&quot;xlabel&quot;</span><span class="p">:</span> <span class="s2">&quot;Number of Principal Components&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ylabel&quot;</span><span class="p">:</span> <span class="s2">&quot;Silhouette Score&quot;</span><span class="p">,</span>
<span class="p">}</span>


<span class="k">def</span> <span class="nf">plot_silhouette_scores_by_pc</span><span class="p">(</span>
    <span class="n">X_reduced</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">classification_labels</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="n">fig_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">ax_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">customizations</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">plt</span><span class="o">.</span><span class="n">Figure</span><span class="p">,</span> <span class="n">plt</span><span class="o">.</span><span class="n">Axes</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Plots silhouette score by number of included principal components.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X_reduced : np.ndarray</span>
<span class="sd">        Dimensionality-reduced dataset</span>
<span class="sd">    classification_labels : Iterable[np.ndarray]</span>
<span class="sd">        Classification results by number of principal components</span>
<span class="sd">    fig_kwargs : dict, optional</span>
<span class="sd">        Keyword arguments passed to the created figure, by default None</span>
<span class="sd">    ax_kwargs : dict, optional</span>
<span class="sd">        Keyword arguments passed to the created axis, by default None</span>
<span class="sd">    customizations : dict, optional</span>
<span class="sd">        Keyword arguments passed to the axis&#39; set() method, by default None,</span>
<span class="sd">        by default None</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Tuple[plt.Figure, plt.Axes]</span>
<span class="sd">        Created figure and axis</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">fig_kwargs</span> <span class="o">=</span> <span class="n">organize_kwargs</span><span class="p">(</span><span class="n">fig_kwargs</span><span class="p">,</span> <span class="n">DEFAULT_FIGURE_KWARGS</span><span class="p">)</span>
    <span class="n">ax_kwargs</span> <span class="o">=</span> <span class="n">organize_kwargs</span><span class="p">(</span><span class="n">ax_kwargs</span><span class="p">,</span> <span class="n">DEFAULT_AXES_KWARGS</span><span class="p">)</span>
    <span class="n">customizations</span> <span class="o">=</span> <span class="n">organize_kwargs</span><span class="p">(</span><span class="n">customizations</span><span class="p">,</span> <span class="n">DEFAULT_CUSTOMIZATIONS</span><span class="p">)</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">x_range</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">classification_labels</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">x_range</span><span class="p">:</span>
        <span class="n">X_subset</span> <span class="o">=</span> <span class="n">X_reduced</span><span class="p">[:,</span> <span class="p">:</span><span class="n">i</span><span class="p">]</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">classification_labels</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">X_subset</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="o">**</span><span class="n">fig_kwargs</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="o">**</span><span class="n">ax_kwargs</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xticks</span><span class="o">=</span><span class="n">x_range</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="n">x_range</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="o">**</span><span class="n">customizations</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span>


<span class="c1">#</span>
<span class="c1"># Silhouette scores by number of K-means clusters</span>
<span class="c1">#</span>

<span class="n">DEFAULT_K_FIGURE_KWARGS</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;figsize&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">)}</span>
<span class="n">DEFAULT_K_CUSTOMIZATION_KWARGS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;title&quot;</span><span class="p">:</span> <span class="s2">&quot;Silhouette Score by $k$&quot;</span><span class="p">,</span>
    <span class="s2">&quot;xlabel&quot;</span><span class="p">:</span> <span class="s2">&quot;$k$&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ylabel&quot;</span><span class="p">:</span> <span class="s2">&quot;Silhouette Score&quot;</span><span class="p">,</span>
<span class="p">}</span>


<span class="k">def</span> <span class="nf">plot_silhouette_scores_by_k</span><span class="p">(</span>
    <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">max_k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">plt</span><span class="o">.</span><span class="n">Figure</span><span class="p">,</span> <span class="n">plt</span><span class="o">.</span><span class="n">Axes</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Plot silhouette scores by k.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : np.ndarray</span>
<span class="sd">        The dataset to fit</span>
<span class="sd">    max_k : int, optional</span>
<span class="sd">        Maximal number of clusters, by default 10</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Tuple[plt.Figure, plt.Axes]</span>
<span class="sd">        Created figure and axis</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">models</span> <span class="o">=</span> <span class="p">[</span><span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">i</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="p">[</span><span class="n">silhouette_score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">labels_</span><span class="p">)</span> <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="p">]</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="o">**</span><span class="n">DEFAULT_K_FIGURE_KWARGS</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">scores</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="o">**</span><span class="n">DEFAULT_K_CUSTOMIZATION_KWARGS</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span>
</pre></div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">plots.silhouette</span> <span class="kn">import</span> <span class="n">plot_silhouette_scores_by_pc</span>


<span class="n">_</span> <span class="o">=</span> <span class="n">plot_silhouette_scores_by_pc</span><span class="p">(</span><span class="n">X_iris_reduced</span><span class="p">,</span> <span class="n">classification_labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>It seems that using only a single principal component yielded not only the best results when compared to the true labels, but also the greatest degree of separation between the clusters (as estimated using <code class="docutils literal notranslate"><span class="pre">silhouette_score</span></code>).</p>
</section>
</section>
</section>
<section id="asd-subtypes-classification">
<h2>ASD Subtypes Classification<a class="headerlink" href="#asd-subtypes-classification" title="Permalink to this heading">#</a></h2>
<p>So, now we know how to implement both PCA and K-means clustering using <code class="docutils literal notranslate"><span class="pre">sklearn</span></code>. Next, we will try and explore the possibility of identifying ASD subtypes using  and  on the <a class="reference external" href="http://fcon_1000.projects.nitrc.org/indi/abide/abide_II.html">ABIDE II</a> dataset, again, based on <a class="reference external" href="https://talyarkoni.org/">Prof. Tal Yarkoni</a>’s workshop in  the <a class="reference external" href="https://neurohackademy.org/">NeuroHackademy</a> 2020 (available <a class="reference external" href="https://github.com/neurohackademy/nh2020-curriculum/tree/master/tu-machine-learning-yarkoni">here</a>). This procedure is somewhat similar to what we did with the iris dataset (in terms of combining PCA and K-means to identify clusters in a dimensionality-reduced space), however, this time the labels are not known to us, and we will try to evaluate whether the results of our analysis produce convincing results.</p>
<p>First, as always, we have to load the data and clean it up a little bit:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">TSV_URL</span> <span class="o">=</span> <span class="s2">&quot;https://raw.githubusercontent.com/neurohackademy/nh2020-curriculum/master/tu-machine-learning-yarkoni/data/abide2.tsv&quot;</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">TSV_URL</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Clean up</span>
<span class="n">IGNORED_COLUMNS</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;age_resid&quot;</span><span class="p">,</span> <span class="s2">&quot;sex&quot;</span><span class="p">]</span>
<span class="n">REPLACE_DICT</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;group&quot;</span><span class="p">:</span> <span class="p">{</span><span class="mi">1</span><span class="p">:</span> <span class="s2">&quot;ASD&quot;</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="s2">&quot;Control&quot;</span><span class="p">}}</span>
<span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">IGNORED_COLUMNS</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">REPLACE_DICT</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This time, however, we’re only interested in ASD positive observations:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">asd_positive</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;group&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;ASD&quot;</span>

<span class="c1"># Feature matrix</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">asd_positive</span><span class="p">]</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">regex</span><span class="o">=</span><span class="s2">&quot;^fs&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">X</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fsArea_L_V1_ROI</th>
      <th>fsArea_L_MST_ROI</th>
      <th>fsArea_L_V6_ROI</th>
      <th>fsArea_L_V2_ROI</th>
      <th>fsArea_L_V3_ROI</th>
      <th>fsArea_L_V4_ROI</th>
      <th>fsArea_L_V8_ROI</th>
      <th>fsArea_L_4_ROI</th>
      <th>fsArea_L_3b_ROI</th>
      <th>fsArea_L_FEF_ROI</th>
      <th>...</th>
      <th>fsCT_R_p47r_ROI</th>
      <th>fsCT_R_TGv_ROI</th>
      <th>fsCT_R_MBelt_ROI</th>
      <th>fsCT_R_LBelt_ROI</th>
      <th>fsCT_R_A4_ROI</th>
      <th>fsCT_R_STSva_ROI</th>
      <th>fsCT_R_TE1m_ROI</th>
      <th>fsCT_R_PI_ROI</th>
      <th>fsCT_R_a32pr_ROI</th>
      <th>fsCT_R_p24_ROI</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2750.0</td>
      <td>306.0</td>
      <td>354.0</td>
      <td>2123.0</td>
      <td>1451.0</td>
      <td>1128.0</td>
      <td>269.0</td>
      <td>1751.0</td>
      <td>1338.0</td>
      <td>632.0</td>
      <td>...</td>
      <td>3.362</td>
      <td>2.827</td>
      <td>2.777</td>
      <td>2.526</td>
      <td>3.202</td>
      <td>3.024</td>
      <td>3.354</td>
      <td>2.629</td>
      <td>2.699</td>
      <td>3.179</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2836.0</td>
      <td>186.0</td>
      <td>354.0</td>
      <td>2261.0</td>
      <td>1584.0</td>
      <td>1241.0</td>
      <td>259.0</td>
      <td>1521.0</td>
      <td>1105.0</td>
      <td>302.0</td>
      <td>...</td>
      <td>2.809</td>
      <td>3.539</td>
      <td>2.944</td>
      <td>2.769</td>
      <td>3.530</td>
      <td>3.079</td>
      <td>3.282</td>
      <td>2.670</td>
      <td>2.746</td>
      <td>3.324</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3382.0</td>
      <td>266.0</td>
      <td>422.0</td>
      <td>2686.0</td>
      <td>1893.0</td>
      <td>1359.0</td>
      <td>234.0</td>
      <td>1889.0</td>
      <td>1545.0</td>
      <td>407.0</td>
      <td>...</td>
      <td>3.349</td>
      <td>3.344</td>
      <td>2.694</td>
      <td>3.030</td>
      <td>3.258</td>
      <td>2.774</td>
      <td>3.383</td>
      <td>2.696</td>
      <td>3.014</td>
      <td>3.264</td>
    </tr>
    <tr>
      <th>5</th>
      <td>3020.0</td>
      <td>390.0</td>
      <td>408.0</td>
      <td>2455.0</td>
      <td>1597.0</td>
      <td>1219.0</td>
      <td>280.0</td>
      <td>2154.0</td>
      <td>1733.0</td>
      <td>528.0</td>
      <td>...</td>
      <td>3.017</td>
      <td>3.202</td>
      <td>3.242</td>
      <td>2.698</td>
      <td>3.035</td>
      <td>2.996</td>
      <td>3.261</td>
      <td>3.310</td>
      <td>3.165</td>
      <td>2.637</td>
    </tr>
    <tr>
      <th>6</th>
      <td>3522.0</td>
      <td>140.0</td>
      <td>471.0</td>
      <td>2935.0</td>
      <td>2007.0</td>
      <td>1483.0</td>
      <td>195.0</td>
      <td>1709.0</td>
      <td>1353.0</td>
      <td>447.0</td>
      <td>...</td>
      <td>2.338</td>
      <td>3.297</td>
      <td>2.941</td>
      <td>2.685</td>
      <td>3.280</td>
      <td>2.912</td>
      <td>2.523</td>
      <td>3.338</td>
      <td>2.926</td>
      <td>3.333</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>992</th>
      <td>3231.0</td>
      <td>202.0</td>
      <td>398.0</td>
      <td>2699.0</td>
      <td>1584.0</td>
      <td>1018.0</td>
      <td>137.0</td>
      <td>1992.0</td>
      <td>1378.0</td>
      <td>557.0</td>
      <td>...</td>
      <td>3.329</td>
      <td>3.192</td>
      <td>2.415</td>
      <td>2.698</td>
      <td>3.230</td>
      <td>2.815</td>
      <td>2.756</td>
      <td>2.872</td>
      <td>3.107</td>
      <td>3.069</td>
    </tr>
    <tr>
      <th>995</th>
      <td>2679.0</td>
      <td>218.0</td>
      <td>309.0</td>
      <td>2041.0</td>
      <td>1473.0</td>
      <td>1100.0</td>
      <td>232.0</td>
      <td>1731.0</td>
      <td>1183.0</td>
      <td>436.0</td>
      <td>...</td>
      <td>2.561</td>
      <td>3.458</td>
      <td>2.758</td>
      <td>2.756</td>
      <td>2.945</td>
      <td>2.560</td>
      <td>2.651</td>
      <td>2.703</td>
      <td>2.248</td>
      <td>3.410</td>
    </tr>
    <tr>
      <th>996</th>
      <td>1739.0</td>
      <td>229.0</td>
      <td>454.0</td>
      <td>1600.0</td>
      <td>1006.0</td>
      <td>755.0</td>
      <td>163.0</td>
      <td>1618.0</td>
      <td>1279.0</td>
      <td>361.0</td>
      <td>...</td>
      <td>2.905</td>
      <td>3.615</td>
      <td>2.658</td>
      <td>2.498</td>
      <td>3.499</td>
      <td>3.429</td>
      <td>3.123</td>
      <td>2.511</td>
      <td>3.530</td>
      <td>3.340</td>
    </tr>
    <tr>
      <th>998</th>
      <td>3393.0</td>
      <td>319.0</td>
      <td>583.0</td>
      <td>2996.0</td>
      <td>2057.0</td>
      <td>1451.0</td>
      <td>259.0</td>
      <td>1773.0</td>
      <td>1455.0</td>
      <td>662.0</td>
      <td>...</td>
      <td>2.684</td>
      <td>3.193</td>
      <td>2.824</td>
      <td>2.728</td>
      <td>3.558</td>
      <td>2.787</td>
      <td>3.765</td>
      <td>2.893</td>
      <td>2.632</td>
      <td>3.485</td>
    </tr>
    <tr>
      <th>1003</th>
      <td>2649.0</td>
      <td>140.0</td>
      <td>307.0</td>
      <td>2359.0</td>
      <td>1446.0</td>
      <td>1003.0</td>
      <td>198.0</td>
      <td>1807.0</td>
      <td>1325.0</td>
      <td>395.0</td>
      <td>...</td>
      <td>3.287</td>
      <td>3.170</td>
      <td>2.494</td>
      <td>2.725</td>
      <td>3.477</td>
      <td>2.850</td>
      <td>3.695</td>
      <td>2.637</td>
      <td>3.263</td>
      <td>2.981</td>
    </tr>
  </tbody>
</table>
<p>463 rows × 1440 columns</p>
</div></div></div>
</div>
<section id="principal-component-analysis-pca">
<h3>Principal Component Analysis (PCA)<a class="headerlink" href="#principal-component-analysis-pca" title="Permalink to this heading">#</a></h3>
<p>We will use PCA to try and “capture” as much of the variance of our 1,440 features using a limited number of principal components.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>

<span class="n">N_COMPONENTS</span> <span class="o">=</span> <span class="mi">20</span>

<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">N_COMPONENTS</span><span class="p">)</span>
<span class="n">X_reduced</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s try and evaluate how well did PCA manage to find small number of components to explain the variance:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="n">plot_explained_variance_ratio</span><span class="p">(</span><span class="n">pca</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_remove-input docutils container">
</div>
<p>It seems like the added value of using more than 2 or 3 components is relatively negligible, with 3 components explaining a total of <span class="pasted-text">49.43</span>% of the total variance.</p>
</section>
<section id="id1">
<h3>K-Means Clustering<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h3>
<section id="id2">
<h4>Clustering Evaluation<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">plots.silhouette</span> <span class="kn">import</span> <span class="n">plot_silhouette_scores_by_k</span>


<span class="n">X_3</span> <span class="o">=</span> <span class="n">X_reduced</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">3</span><span class="p">]</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plot_silhouette_scores_by_k</span><span class="p">(</span><span class="n">X_3</span><span class="p">,</span> <span class="n">max_k</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The best degree of separation was obtained for <span class="math notranslate nohighlight">\(k=2\)</span>. Let’s visualize the two clusters and obtain some qualitative understanding of how well (or badly) our model did:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">classification_labels</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_3</span><span class="p">)</span><span class="o">.</span><span class="n">labels_</span>
<span class="n">plot_reduced</span><span class="p">(</span><span class="n">X_3</span><span class="p">,</span> <span class="n">classification_labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/f4d321c4acec1e3e510e7196ac4ffd450aa35c1268c565f28bad1db8042efc09.png" src="../../_images/f4d321c4acec1e3e510e7196ac4ffd450aa35c1268c565f28bad1db8042efc09.png" />
<img alt="../../_images/466b5c3919a6581abd8457c87a5e70a603160104f5f7b46ebb5508acb83a15f6.png" src="../../_images/466b5c3919a6581abd8457c87a5e70a603160104f5f7b46ebb5508acb83a15f6.png" />
<img alt="../../_images/04bd85f8bd2cee465ec879b0bf43ef421486585cdca1105486ef47fed24742f0.png" src="../../_images/04bd85f8bd2cee465ec879b0bf43ef421486585cdca1105486ef47fed24742f0.png" />
<img alt="../../_images/88e8a8ce429acd2cc225cc116f937fe274655d90ada75c54b41431fc9e49e6e8.png" src="../../_images/88e8a8ce429acd2cc225cc116f937fe274655d90ada75c54b41431fc9e49e6e8.png" />
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "55e0ac7166ec41cf8eb93b6da0e0dcc6", "version_major": 2, "version_minor": 0}</script></div>
</div>
<p>Indeed, it seems our model’s ability to cluster ASD subtypes using three principal components is rather poor.</p>
<p><img alt="Back to the Drawing Board" src="https://images-wixmp-ed30a86b8c4ca887773594c2.wixmp.com/f/5cac04eb-d473-4265-86ab-c8c146757448/d8ngxde-b1711ad7-d0bf-4357-8984-25473d92df19.png/v1/fill/w_763,h_707,q_80,strp/well__back_to_the_old_drawing_board_by_comicadreams_d8ngxde-fullview.jpg?token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJ1cm46YXBwOiIsImlzcyI6InVybjphcHA6Iiwib2JqIjpbW3siaGVpZ2h0IjoiPD03MDciLCJwYXRoIjoiXC9mXC81Y2FjMDRlYi1kNDczLTQyNjUtODZhYi1jOGMxNDY3NTc0NDhcL2Q4bmd4ZGUtYjE3MTFhZDctZDBiZi00MzU3LTg5ODQtMjU0NzNkOTJkZjE5LnBuZyIsIndpZHRoIjoiPD03NjMifV1dLCJhdWQiOlsidXJuOnNlcnZpY2U6aW1hZ2Uub3BlcmF0aW9ucyJdfQ.mEuPF3SgwRYbZFdA5Bga04bN936SQ4EzLA7FyWUz1XY" /></p>
</section>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapters/chapter_08"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../chapter_07/exercise_07.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Exercise VII: Decision Trees and Random Forests</p>
      </div>
    </a>
    <a class="right-next"
       href="../chapter_09/exercise_09.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Exercise IX: The Haxby Experiment (2001)</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#iris-dataset">Iris Dataset</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#set-up">Set up</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dimensionality-reduction-using-principal-component-analysis-pca">Dimensionality Reduction using Principal Component Analysis (PCA)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#k-means-clustering">K-means Clustering</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#clustering-evaluation">Clustering Evaluation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#asd-subtypes-classification">ASD Subtypes Classification</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#principal-component-analysis-pca">Principal Component Analysis (PCA)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">K-Means Clustering</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Clustering Evaluation</a></li>
</ul>
</li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Dr. Shlomi Lifshits, Gal Kepler, Zvi Baratz
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>